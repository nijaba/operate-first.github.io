{"componentChunkName":"component---node-modules-lekoarts-gatsby-theme-minimal-blog-core-src-templates-post-query-tsx","path":"/blog/why-sre","result":{"data":{"post":{"slug":"/blog/why-sre","title":"Why SRE?","date":"23.05.2022","tags":null,"description":null,"canonicalUrl":null,"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Why SRE?\",\n  \"date\": \"2022-05-23T00:00:00.000Z\",\n  \"slug\": \"/why-sre\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", null, \"Why SRE?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Author(s):@david-martin\"), mdx(\"br\", null), \"\\n\", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Contributor(s):Narayanan Raghavan, Jay Ferrandini, Tony Fister, Aditya Konarde, Tim Waugh\"), mdx(\"br\", null)), mdx(\"p\", null, \"There are lots of reasons you may be thinking about Site Reliability Engineering (SRE), both the role (Engineer) and the concept (Engineering).\\nThe role can have a very specific meaning in your organisation, which is fine.\\nIn fact it needs to be specific so you can hire accordingly, onboard and train people to do a specific job.\\nIt's your implementation of the SRE principles.\"), mdx(\"p\", null, \"The SRE concept and principles are born from Google and their \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://sre.google\"\n  }, \"various publications\"), \".\\nPrinciples such as \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Embracing Risk\"), \", \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Service Level Objectives\"), \" and \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Eliminating Toil\"), \".\\nFollowing on from the principles are practices like \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Managing Incidents\"), \", a \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Postmortem Culture\"), \" and \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Testing for Reliability\"), \".\\nHere, we\\u2019ll present some case studies in Red Hat where SRE is being practised and try to understand the reasons for choosing SRE and how it was applied.\"), mdx(\"h2\", null, \"Case Study 1: Managed OpenShift\"), mdx(\"p\", null, \"At Red Hat there are many SRE teams, all of which evolved a little differently to solve different problems.\\nSo the reasons to start 'doing' SRE were varied.\\nOne example is the SRE team behind Managed OpenShift.\\nIt was established out of frustration with not being able to move fast enough.\\nThe time it took to provision clusters for customers limited how fast they could grow.\\nThe ops team at the time spent a lot of time 'hands on' with clusters, managing them and dealing with escalations.\\nThe concept of SRE was discussed as a way to reorganise and think about the problem differently.\"), mdx(\"p\", null, \"It started with some reasonable goals e.g. Can we halve the time it takes to create a cluster, thereby allowing double the amount per year?\\nAs that goal was reached, it got revised again and again until it got to the point where it didn't matter how many clusters needed to be created.\\nThe SRE team had sufficiently automated away so much of the manual processes around creation that it was a non-event for a new cluster to be created.\"), mdx(\"p\", null, \"Having an initial goal to rally around can help when forming a new team or making a transition.\\nThere are many other aspects that can boost the effort as well.\\nHiring software engineers who have a 'systems mindset' and can think about scale was important here.\\nA lot of focus was put on the processes and people when hiring and building the team rather than the technology.\\nEmbracing risk and removing any fear of retribution was important to establish early on.\\nAs was having a foundation of trust and building on it.\\nIn general, focus was on the people, the practice, education, training and enablement.\"), mdx(\"p\", null, \"You can read more about this transition in this blog post from 2020, \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://cloud.redhat.com/blog/from-ops-to-sre-evolution-of-the-openshift-dedicated-team\"\n  }, \"From Ops to SRE: Evolution of the OpenShift Dedicated Team\")), mdx(\"h2\", null, \"Case Study 2: Ansible Automation Platform on Azure\"), mdx(\"p\", null, \"The team behind the Ansible Automation Platform is a relatively new team.\\nIt is an ensemble team made up of developers and SREs.\\nThe SRE team's job is to ensure the service deploys, stays running and is kept up to date.\\nIt runs as a Managed Application on Azure, which was a major reason for establishing a new SRE team.\\nThere are other 'centralised' SRE teams at Red Hat that enable services running on OpenShift.\\nHowever, this team needed to specialise in Ansible Automation Platform as well as Azure.\\nThe reasons for 'SRE' specifically were twofold.\\nIt was already an established practice in Red Hat with various practicing teams to draw knowledge from.\\nAlso, the management team had previous experience with many of the SRE principles and practices.\"), mdx(\"p\", null, \"One the biggest motivating factors for this team is pain.\\nBoth customer pain and the team's pain.\\nAn example of customer pain would be not being able to purchase and deploy at the press of a button.\\nThe team saw this from the customers perspective and looked at ways of automating away the manual steps and engagements.\\nThey identified areas where a deploy could fail late in the process and someone would have to manually reset and trigger things again.\\nThe solution here was adding pre-installation checks.\\nIt's a reactive model, but it's also \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/operate-first/sre/blob/main/sre_maturity.md#toil-management-and-operational-improvements\"\n  }, \"actively managing TOIL early on\"), \".\\nThe concept of tying your decisions to what the customer cares about and measuring it is an important one for this team.\\nThey are establishing Service Level Indicators (SLIs) and Objectives (SLOs) in an effort to be more proactive.\"), mdx(\"p\", null, \"The management team deliberately hired from a diverse group of backgrounds.\\nThe focus was on hiring people who could lead & speak their mind.\\nPeople who could think from the bottom up, as management wasn't going to have all the ideas.\\nThey recognised the importance of a good education plan.\\nWhen hiring for the team it was always going to be a challenge to get everyone up to the same level of confidence.\\nSome people have a lot of Ansible skills, while some have a lot of Azure skills.\\nIt's important to invest in the team by recommending courses and allowing time for people to upskill.\"), mdx(\"h2\", null, \"Case Study 3: Services on OpenShift\"), mdx(\"p\", null, \"There's an SRE team in Red Hat called the SRE Services (or SRES) team.\\nAt the time of writing they manage roughly 50 services.\\nThese services range from customer facing services to ancillary services that support those, all of which run on OpenShift.\\nThe team uses a gitops model to normalise things across services and manage building, deploying, configuring & upgrading things.\\nThis model allows teams to build a service and onboard them to this central SRE team by following standardised processes and using automation.\\nHowever, it took a while to get to this point. This SRES team was a natural evolution of a bigger plan.\"), mdx(\"p\", null, \"Building on the Managed OpenShift SRE story in Case Study 1, the OpenShift platform reached a high level of reliability, maturity and scale.\\nThere was a transition point to start introducing services to the platform.\\nThe SRE model was a success already so it made sense to use that same model to solve this new problem.\\nThe SRES team was formed and tasked with solving that problem.\"), mdx(\"p\", null, \"Git was central to change management for this team.\\nEverything went through git.\\nPull requests had checks and automated pipelines for rolling out changes when they merged.\\nConfiguration was declarative and the service contract was clearly defined in the versioned json schema.\\nA standard set of monitoring tools was adopted and SLOs were starting to be defined and used.\\nDriving principles were automation, limiting toil and scaling.\\nThe team knew they had to scale to many services.\"), mdx(\"p\", null, \"All this came with a trade off.\\nEvery service had to fit into the model, or else the model had to change and adapt.\\nOne such adaption was the idea of an 'Add-On' to an OpenShift cluster.\\nA service that can be installed and managed on a customer's existing Managed OpenShift cluster.\\nAdd-Ons were managed slightly differently than all other services.\\nIt was still gitops, but on non-SRES owned infrastructure.\\nIt was a sufficiently different model with different concerns that a new SRE team emerged to focus on this problem.\\nLike before, the SRE model was working well, so it made sense to continue with those concepts and principles to solve this new problem.\"), mdx(\"p\", null, \"This new team drives hard on automation, reliability and self service.\\nThey always try to automate something before accepting toil.\\nFor this team, pagers are a last resort and are tied to SLIs and SLOs.\\nThese teams are all on-call, but it's not their primary responsibility to be on-call.\\nAn important mechanism for driving this in teams developing services is communication.\\nIt's important to have a shared channel for highlighting these things on a regular basis.\\nThis can't be done daily with each development team as it just won't scale.\\nInstead there's weekly checkpoints where bidirectional sharing of upcoming changes and requests can happen.\"), mdx(\"p\", null, \"When building this team, the focus was on development skills first.\\nThere was a lot of effort put into a pipeline for automating things.\\nAs things progressed, there was a need for people with operational experience.\\nParticularly as the number of customers increased.\\nWhen interviewing, asking how someone dealt with situations, pages and on call was very telling.\\nQuestions like 'Are they blameless?' or 'Are they accountable?'.\\nYou need people that will take accountability and drive projects.\\nThe team is very heavy on talking with each other while onboarding and reading documentation.\\nUnderstanding the \\u2018why\\u2019 is important before transitioning to actual work.\\nHaving a core region of people made it easier to bring others up to speed and plan for 24/7 on-call.\"), mdx(\"h2\", null, \"Case Study 4: Software Production\"), mdx(\"p\", null, \"There is a group in Red Hat called Software Production.\\nThe group creates and maintains tools and services used in the process of building Red Hat\\u2019s enterprise-grade software.\\nIn this group there was a team of engineers called \\u2018SysOps\\u2019.\\nIt was a central team that other dependent teams could reach out to for operational things like provisioning VMs, maintenance tasks on linux hosts and granting appropriate permissions in several different applications with their own auth models.\\nThe team's approach to service reliability was based around response times to tickets, which stakeholders would create.\\nA few problems were identified, which led to rethinking the whole process:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The process wasn\\u2019t scaling. As ticket volume increased, the team size needed to increase with it. Scaling the team linearly with the volume of work was not sustainable.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The expectation that stakeholders would be the ones finding reliability issues before we did was flawed.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"We wanted to provide a better career path to associates.\")), mdx(\"p\", null, \"All these things culminated in a reorg where new teams were formed, each with embedded SREs.\\nAn SRE \\u2018League\\u2019 was established where all the SREs from the different teams got together regularly to discuss common concerns.\\nA number of key SRE principles and practices were adopted and spread throughout the wider group via the individual SREs.\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"The group has more than 100 services to keep running, so they built a catalog and classified them according to criticality. The criticality then maps to an SLO. The corresponding SLIs are defined in this catalog as well. Indicators range from internet & internal probes, prometheus metrics, CI job success rates to executing database queries periodically. This has helped to observe what\\u2019s actually happening in the services to the point where introducing an Error Budget policy is being considered.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"The concept of TOIL has also been introduced via a technical improvement policy. Some teams use story points to estimate the size and scope of issues on their backlog. Each quarter a certain percentage of story points are set aside to improve the lives of the team by reducing TOIL and automating things.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Doing Root Cause Analysis (RCA) and post mortems has become a regular part of running services. It allows teams to prioritise the outcome of post mortems in upcoming sprints with a shared understanding of why they are prioritised.\")), mdx(\"h2\", null, \"Conclusion\"), mdx(\"p\", null, \"There are many reasons for choosing to follow SRE principles and practices.\\nIt could be a way to shift the focus of an ops or devops team to reliability, scaling and automation.\\nPerhaps it\\u2019s something you\\u2019re already familiar with and you want to put it into practice with a new team.\\nMaybe it\\u2019s already working well for you and you have a new problem to solve, so you seed a new team with experienced SREs.\\nEach of these reasons has its own challenges around building a team, which principles to focus on first and finding the right time to introduce new principles.\\nHaving an initial problem to solve and rally behind helps you make those initial decisions.\\nHowever, the principles and practices don\\u2019t change in SRE.\\nIf you believe in them, let them guide you and your own team's implementation of them.\"));\n}\n;\nMDXContent.isMDXComponent = true;","excerpt":"Why SRE? Author(s):@david-martin \n Contributor(s):Narayanan Raghavan, Jay Ferrandini, Tony Fister, Aditya Konarde, Tim Waugh There are lots…","timeToRead":7,"banner":null}},"pageContext":{"slug":"/blog/why-sre","formatString":"DD.MM.YYYY"}},"staticQueryHashes":[]}